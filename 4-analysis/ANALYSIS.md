# FLTG 구현 결과 고찰

## 1. 실험 결과 분석

### 정량적 결과
- Baseline (공격 없음): 98.5%
- ROP + FedAVG: 98.4% (-0.1%p)
- ROP + Trimmed-Mean: 98.2% (-0.3%p)
- ROP + Krum: 98.1% (-0.4%p)
- ROP + FLTG: 97.1% (-1.4%p)

### 핵심 발견사항
1. FLTG가 논문 주장과 달리 가장 낮은 성능을 보임
2. 심지어 방어 없는 FedAVG보다 1.3%p 낮음
3. 초기 수렴 속도가 매우 느림 (Epoch 1: 63.6% vs 다른 방법들 75-90%)

## 2. 왜 이런 결과가 나왔나?

### 가설 1: Dynamic Reference Selection의 역설
**논문 의도**: "정상이지만 가장 독특한" 클라이언트를 참조점으로 선택

**현재 구현**:
```python
cos_sims_with_prev = [F.cosine_similarity(g, g_prev, dim=0) for g in filtered_inputs]
ref_idx = cos_sims_with_prev.index(min(cos_sims_with_prev))
```

**문제점**:
- 이전 글로벌 모델과 가장 다른 업데이트 = 반드시 "좋은 독특함"은 아님
- ROP 공격의 특성: 의도적으로 이전 방향과 다른 방향 제시
- 결과: 악의적 클라이언트가 참조점이 될 가능성 높음
- 파급효과: 참조점이 악의적이면 가중치 시스템 전체가 역전됨

### 가설 2: 과도한 필터링
**Step 2: ReLU-clipped filtering**
- 서버 그래디언트와 cos_sim < 0인 모든 클라이언트 제거
- 문제: Non-IID 환경에서 정상 클라이언트도 서버와 방향이 많이 다를 수 있음
- 결과: 필요한 정보를 가진 정상 클라이언트까지 제거

### 가설 3: 가중치 부여 방식의 모순
**현재 로직**:
```python
score = 1 - cos_sim(g_i, g_ref)  # 참조점과 다를수록 높은 가중치
```

**의도**: Non-IID 다양성 존중
**실제**: 참조점이 악의적이면, 정상 클라이언트에 낮은 가중치 부여

### 가설 4: 서버 루트 데이터셋 크기 부족
- 현재: 100개 샘플만 사용
- 문제: MNIST 10개 클래스에 대해 클래스당 평균 10개만 사용
- 결과: 서버 그래디언트가 편향될 가능성

## 3. 논문과 구현의 차이

### 논문에서 주장하는 FLTG의 강점
1. "50% 이상의 악의적 클라이언트에서도 강건함"
2. "기존 방법들보다 우수한 성능"
3. "Non-IID 환경에서 효과적"

### 우리 실험 결과
1. 20% 악의적 환경에서도 기존 방법보다 낮음
2. 방어 없는 FedAVG보다도 낮음
3. Non-IID 처리가 오히려 역효과

### 차이의 원인
1. **구현 불일치**: 논문의 정확한 수식 재확인 필요
2. **실험 환경**:
   - 논문: CIFAR-10, 더 많은 epoch, 다양한 공격
   - 우리: MNIST, 10 epochs, ROP만
3. **하이퍼파라미터**: 루트 데이터셋 크기, 필터링 임계값 등

## 4. 흥미로운 관찰

### FedAVG의 예상외 강건함
- 방어 없이도 98.4% 달성
- ROP 공격에 대해 단 -0.1%p만 감소
- 이유: MNIST가 단순하고, 20% 악의적 비율이 낮기 때문

### 전통적 방어 기법의 안정성
- Krum, Trimmed-Mean 모두 안정적 성능
- 복잡한 알고리즘이 항상 좋은 것은 아님
- "Simple is better" 원칙의 증명

### FLTG의 trade-off
- 강력한 필터링 → 초기 학습 매우 느림
- 복잡한 가중치 시스템 → 잘못되면 역효과
- 다단계 방어 → 각 단계마다 오류 누적 가능

## 5. 개선 방향

### 단기 (빠른 수정)
1. **참조 클라이언트 선택 개선**
   ```python
   # 최소값 대신 중간값 사용
   median_idx = len(cos_sims_with_prev) // 2
   ref_idx = sorted(range(len(cos_sims_with_prev)),
                    key=lambda i: cos_sims_with_prev[i])[median_idx]
   ```

2. **서버 그래디언트 가중치 증가**
   ```python
   # 서버 그래디언트를 aggregation에 직접 포함
   aggregated = 0.5 * g0 + 0.5 * sum(w * g for w, g in zip(weights, normalized_inputs))
   ```

3. **루트 데이터셋 크기 증가**
   - 100개 → 500개 또는 1000개

### 중기 (알고리즘 수정)
1. **2단계 필터링**
   - Step 1: 서버와의 유사도로 1차 필터링 (임계값 완화)
   - Step 2: 클라이언트 간 상호 유사도로 2차 검증

2. **적응적 가중치**
   - 학습 초기: 서버 그래디언트에 높은 가중치
   - 학습 후기: 클라이언트 다양성에 높은 가중치

3. **참조점 앙상블**
   - 단일 참조점 대신 top-k 참조점 사용
   - 각 참조점에 대한 가중치의 평균 사용

### 장기 (근본적 재설계)
1. **논문 원저자와 소통**
   - 정확한 구현 세부사항 확인
   - 공식 코드 존재 여부 확인

2. **더 강한 실험 환경**
   - 악의적 비율 30%, 40%, 50% 테스트
   - IPM, ALIE 등 다른 공격으로 테스트
   - 50-100 epochs 장기 실험

3. **이론적 분석**
   - 각 단계별 수학적 보장 확인
   - 최악의 경우(worst-case) 시나리오 분석

## 6. 학술적/실무적 시사점

### 학술적 관점
1. **재현성 문제**: 논문의 결과를 재현하지 못함 → 구현 세부사항의 중요성
2. **복잡성의 역설**: 더 복잡한 알고리즘이 항상 더 나은 것은 아님
3. **벤치마크의 중요성**: 간단한 baseline과의 비교 필수

### 실무적 관점
1. **실용성**: Krum, Trimmed-Mean 같은 간단한 방법이 더 신뢰할 수 있음
2. **비용 대비 효과**: FLTG는 계산 비용이 높지만 효과는 낮음
3. **디버깅 용이성**: 단순한 알고리즘이 문제 발견/수정이 쉬움

### 연구 윤리적 관점
1. **투명성**: 논문이 모든 세부사항을 명시해야 함
2. **코드 공개**: 재현성을 위해 공식 구현 공개 필요
3. **부정적 결과도 중요**: 우리의 실패도 의미 있는 결과

## 7. 최종 결론

### 무엇을 배웠나?
1. **논문 ≠ 실제**: 논문의 주장을 무조건 신뢰하면 안 됨
2. **구현의 중요성**: 작은 차이가 큰 성능 차이를 만듦
3. **실험의 가치**: 직접 실험해봐야 진실을 알 수 있음

### 프로젝트의 가치
1. **실패도 성공**: FLTG의 한계를 발견한 것 자체가 기여
2. **재현 연구**: 다른 연구자들에게 경고 역할
3. **개선 기회**: 더 나은 알고리즘을 만들 수 있는 통찰

### 다음 단계
1. 논문 저자에게 연락하여 구현 검증
2. 공식 코드가 있다면 비교 분석
3. 개선된 버전 제안 및 실험
4. 결과를 기술 블로그나 워크샵에 발표

---

**"실패는 성공의 어머니"** - 이번 실험에서 FLTG가 예상보다 낮은 성능을 보인 것은
실패가 아니라, 알고리즘의 실제 동작을 이해하고 개선점을 찾는 귀중한 과정입니다.