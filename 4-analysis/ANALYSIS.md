# FLTG 실험 결과 분석

## 1. 문제 정의
메인 논문에서 보고한 FLTG 성능이 극단적 Non-IID 환경에서 반복되지 않았고, 일부 구간에서는 기존 방어(FedAVG, Krum 등)가 더 안정적으로 보였다. 원인 규명과 개선 방향 도출을 위해 다음 세 가지 가설을 세우고 순차적으로 검증했다.

## 2. 가설 설정

| 가설 | 핵심 질문 | 관련 변수 |
| --- | --- | --- |
| 가설 1. 데이터 분포의 차이 | 논문과 다른 샘플링/편향 구조가 성능에 영향을 줬는가? | Sampling 방식, Dirichlet α, bias JSON |
| 가설 2. 데이터셋의 크기/복잡성 | CIFAR-10 등 복잡한 데이터가 학습 난도를 높였는가? | Dataset 유형, 모델 용량, Epoch 수 |
| 가설 3. 학습 하이퍼파라미터 | 논문에 없는 세부 설정이 성능 저하의 원인인가? | Epoch, Batch Size, Client 수, LR 등 |

각 가설은 실제 재현 과정에서 제어하거나 바꿀 수 있는 변수에 집중했다.

## 3. 가설 검증

### 3.1 가설 1 – 데이터 분포 차이
- **실험 설정**: `mnist_bias_utils.py`로 생성한 `root_bias_<p>.json`을 사용해 bias {0.1, 0.5, 0.8} 각각에 대해 수동 샘플링을 적용하고 `run_fig3_mnist.py`로 동일 조건 실험.
- **관찰**: 분포를 논문과 유사하게 맞춰도 FLTG와 FL-Trust 모두 특정 구간에서 정확도가 급락했으며, FedAVG(공격 없음) 기준선과 격차가 유지되었다(`README.md:193`).
- **결론**: 분포 차이는 주된 원인이 아니라고 판단. 이후 가설 2, 3에 집중.

### 3.2 가설 2 – 데이터셋의 크기·복잡성
- **실험 설정**: CIFAR-10 기반 실험을 잠시 중단하고 MNIST와 MNISTNET으로 동일 시나리오를 재구성(`run_fig4_mnist.py`).
- **관찰**: MNIST 환경에서는 30% 이하 Byzantine 비율에서 모든 방어가 98% 이상 수렴했고, 극단 조건에서도 FLTG가 FedAVG 대비 8–10%p 이상 앞섰다(`README.md:201`, `README.md:208`).
- **결론**: 데이터 복잡도가 높을수록 FLTG 초기 수렴이 타 방어 대비 불리해진다는 가설이 타당. 다만 MNIST처럼 단순한 데이터에서는 우수성을 재확인했다.

### 3.3 가설 3 – 학습 하이퍼파라미터
- **실험 설정**: CIFAR-10 실험을 다시 실행하되 Epoch 50, mini-batch 64, 클라이언트 80명 등 논문 명시 설정을 충실히 따르고, bias별/Byzantine별 로그를 `new_run_fig3_cifar.py`로 수집.
- **관찰**: 하이퍼파라미터를 조율한 뒤에는 bias 0.1, 0.5 구간에서 FLTG가 FL-Trust 대비 최대 10%p, FedAVG 대비 7%p까지 격차를 벌렸다(`README.md:290-291`). 다만 bias 0.8에서 여전히 변동성이 커 장시간 학습이 필요했다.
- **결론**: 부정확한 하이퍼파라미터 세팅이 성능 저하의 중요한 원인. 복잡한 데이터에서는 장시간 학습 및 안정화가 필수이며, 로컬 환경에서 완전한 재현까지 5~7일 정도의 연산 시간이 필요할 것으로 추산된다.

## 4. 종합 정리
1. **데이터 분포**만 맞춘다고 성능이 자동으로 회복되지는 않는다. 복잡한 데이터에서는 오히려 학습 시간이 절대적으로 부족했다.
2. **데이터 복잡성**이 낮은 MNIST 실험에서는 FLTG의 강점이 명확했으며, 극단 경우에도 50% Byzantine 조건에서 다른 방어가 실패하는 동안 96% 정확도까지 회복했다(`README.md:201`).
3. **학습 하이퍼파라미터**를 논문 수준으로 맞춰주면 CIFAR-10에서도 FLTG의 장점이 나타났다. 반대로 빠른 프로토타입 세팅에서는 FLTG가 가장 느리게 수렴한다는 `4-analysis/ANALYSIS.md:15`의 기존 관찰과도 일치한다.

## 5. 다음 단계
1. **Bias 0.8 이상, Byzantine 90% 구간**에서 더 긴 학습과 다양한 optimizer를 시험해 변동성을 줄인다.
2. **Reference vector 선택·가중치 계산 개선**(README 개선안 참조)을 실험 코드에 추가해 FLTG 초기 수렴을 가속한다.
3. **시각화 자동화**: `5-visualization/plot_fig3_mnist.py` 등 스크립트로 최신 로그를 다시 그려 비교 보고서를 업데이트한다.

